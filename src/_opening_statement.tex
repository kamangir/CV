\onehalfspace
\textbf{\large Canadian Data Scientist proficient in Machine Vision/Deep Learning with 10+ years of experience in 
disruptive North American companies.}
\singlespace

\vspace{1cm}

In the late nineties, I was finishing my undergraduate studies in electrical engineering, when I received word that the biomechanics laboratory had acquired a frame-grabber and were looking for someone to help them code up the device into a gait analysis system, i.e. two camcorders captured a person on the catwalk and our software produced  a csv file with the coordinates of the person's joints. Later on, we added pedobarography (foot pressure analysis) to the system. 

\vspace{0.5cm}
Image processing was applied mathematics on images, and I started a master's program on color image processing at the mathematics  science department in 2003. This was an introduction to higher mathematical concepts such as linear spaces and principal component analysis (PCA). This latter one introduced me to watermarking, color transfer (to colored and grayscale images), and classification, and more importantly to the realization that to arrive at a high-value image processing algorithm one needs to be comfortable with the underlying mathematical models. 

\vspace{0.5cm}
By 2005, I had moved to Canada and had started my Ph.D. on optimization. I found it fascinating that a complex system can be modelled  and analyzed mathematically to produce valuable insights. For my Ph.D. thesis, I carried out this type of analysis on a capacity  maximization problem in a cellular system and showed a solution strategy.  During that period I also worked as a research assistant on video-on-demand network design and maintenance using a multi-layer  fuzzy clustering model.

\vspace{0.5cm}
I joined Epson Canada in 2009. For six and a half years, I worked on commercial applications, including visual inspection, symbology detection, 3d object detection and pose estimation, camera calibration, augmented and virtual reality, 3d scan/display systems, head-mounted displays, and robotics. Multiple patents came from that work. I also expanded my work on fuzzy clustering and published several journal papers during this period.

\vspace{0.5cm}
In 2015 I joined Intellijoint Surgical (IJS). This was my first startup experience and a deep dive into cost optimization within the framework of an image processing system. IJS's infrared monocular camera is an exquisite technology that allows for high-accuracy pose estimation in the operating room. I had the opportunity to work on the tracking system and its applications, including an in-vivo infrared laser scannerâ€”more info in the patents section.

\vspace{0.5cm}
I developed my first learning-enabled machine vision application in 2016 for Fio. An Andriod-based device ran our ML models to recognize rapid diagnostic tests (RDT) and read their results. An RDT is a cassette, 5-10 centimetres (2-4 inches) longs, on which one or multiple active membranes allow for rapid testing for diseases such as Malaria, HIV, Dengue, Zeka, etc. I wrote this code in Matlab and then machine-translated it to python. 

\vspace{0.5cm}
Betterview allowed me to experiment with a nuclear network that consumes aerial images and other types of data to produce property insights. By this time I had already spent two years on Coursera, and other online MOOC resources, and I was entirely comfortable with python and its machinery for scientific programming (numpy, scipy, seaborn, pandas, etc.), and more specifically machine/deep learning (tensorflow, scikit-learn). Additionally, hands-on experience allowed me to develop massive gpu saving strategies and to obtain cloud programming (aws/gcs) and efficient human annotation management (mturk/dls/boutique) skills.

\vspace{0.5cm}
In late 2018 I started a self-funded exploratory/educational project that aimed at developing a mobile robot that could recognize its operator and maneuver in its environment. As the robot was subsequently named, Blue is a Sphero RVR connected to an ad-hoc mesh of Raspberry Pis and other linux machines. Blue perceives its environment through rgb images as well as dsm+imu (through an intel realsense camera). The code for Blue is written in bash and python (including django). Blue uses aws s3/rds for file/data storage and aws sqs for communication. 

\vspace{0.5cm}
Blue is a continuous machine learning system that manages the full circle of data acquisition, human annotation collection, model training and retraining, evaluation, and inference. For a live view of Blue's internal processes, refer to \url{http://kamangir.net/shamim/}{kamangir.net/shamim}. Full source code for Blue is contained in the following githup repos: \url{https://github.com/kamangir/mypy}{github.com/kamangir/mypy} and \url{https://github.com/kamangir/Dec8}{github.com/kamangir/Dec8}. Access will be granted upon request.

\vspace{0.5cm}
More information and full text of patents and publications are available at \url{http://abadpour.com}{abadpour.com}.

\vspace{1.5cm}
