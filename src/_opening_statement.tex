\onehalfspace
\textbf{\large Canadian Data Scientist proficient in Machine Vision/Deep Learning with 10+ years of experience in 
disruptive North American companies.}
\singlespace

\vspace{1cm}

In the late nineties I was finishing my undergraduate studies in electrical engineering, when I received word that
the biomachanics laboratory had acquired a frame-grabber and were looking for someone to help them code up the device
into a gait analysis system, i.e. two camcorders captured a person on the catwalk and our software was required to produce 
a csv file with the coordinates of the person's joints. Later on, we added pedobarography (foot pressure analysis) to the 
system. 

Image processing was in effect applying mathematics on images and I started a master's program on color image processing. 
This was an introduction to higher mathematical concepts such as linear spaces and principal component anslysis (PCA). This
latter one introduced me to watermarking, color transfer (to colored and grayscale images), and classification, and more 
importantly to the realization that to arrive at a high value image processing algorithm one needs to be comfortable with
the underlying mathematical models. 

By this time, I had moved to Canada, and had started my Ph.D. on optimization. I found it fascinating that a complex system can be 
modeled and analyzed mathematically in order to produce valuable insights. For my Ph.D. thesis I carried out this type of 
analysis on a capacity maximization problem in a cellular system and showed that there was a solution strategy to the problem. 
During that period I also worked as a research assistant on video-on-demand network design and maintenance using a multi-layer 
fuzzy clustering model.

I joined Epson Canada in 2009 and for six and a half years I worked on commercial applications including visual inspection, 
symbology detection, 3d object detection and pose estimation, camera calibration, augmented and virtual reality, 3d scan/display 
systems, head-mounted displays, and robotics. Multiple patents came of of this work. I also expanded my work on fuzzy cluistering 
and published a number of journal papers during this period.

in 2015 I joined Intellijoint Surgical (IJS). This was my first startup experience and a deep dive into cost optimization within 
the framework of an image processing system. IJS's infrared monocular camera is an exquisite piece of technology that allows for 
high accurate pose estimation in the OR. I had the opporunity to work on the tracking system and its applications, including 
an in-vivo infrared laser scanner. More info in the patents section.

I developed my first machine vision application in 2016 for Fio, wherein an Andriod-based device ran our ML models to recognize 
rapid diagnostic tests (RDT) and read their results. An RDT is a cassete, 5-10 centimeters longs, on which one or multiple active
membranes allow for rapid testing of diseases such as Malaria, HIV, Dengue, Zeka, etc. I wrote this code in Matlab and then machine 
translate it Python. 

BetterView allowed me to experiment with a full-blown nuclear network that consumes aerial images and other type data in order to 
produce property insights. By this time I had already spent two years on Coursera, and other online MOOT resources, and was completely 
comfotable with Python and its machinery for scientific programming (numpy, scipy, seaborn, pandas, etc.), and more specifically 
Machine/Deep Learning (tensorflow, scikit-learn). Additionally, hands-on experience allowed me to develop massive gpu saving strategies 
as well as cloud programming (aws/gcs) and efficient human annotation management (mturk/dls/boutique).

In late 2018 I started a self-funded exploratory/educational project that aimed at developing a mobile robot that could recognize its
operator and manouver in its environment. Blue, as the robot was later named, is a Sphero RVR connected to an ad-hoc mesh of Raspberry 
Pis and other linux machines. Blue perceives its environment through RGB images as well as DSM (through an intel realsense camera). The 
code for Blue is written in bash and Python (including django). Blue uses AWS s3/rds for file/data storage and AWS sqs for communication. 

Blue is a continous machine learning system that manages the full circle of data acquisition, human annotation collection, model training and
retraining, and inference. For a live view of Blue's internal processes refer to http://kamangir.net/shamim/. Full source code for Blue is 
contained in the following githup repos: https://github.com/kamangir/mypy and https://github.com/kamangir/Dec8. Access will be granted upon 
request. 


\vspace{0.5cm}
More information and full text of patents and publications are available at \emph{http://abadpour.com}.

\vspace{1.5cm}
